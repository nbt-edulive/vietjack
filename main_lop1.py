import requests
from bs4 import BeautifulSoup
import html2text
import os
import re
import json
import time
import logging
from datetime import datetime
from urllib.parse import urljoin, urlparse
from pathlib import Path
from dotenv import load_dotenv
load_dotenv()

# Cáº¥u hÃ¬nh Telegram Bot
TELEGRAM_BOT_TOKEN = os.getenv("BOT_TOKEN_1") # Thay YOUR_BOT_TOKEN báº±ng token cá»§a bot Telegram
TELEGRAM_CHAT_ID = os.getenv("CHAT_ID")  # Thay YOUR_CHAT_ID báº±ng chat ID cá»§a báº¡n
ENABLE_TELEGRAM = True  # Äáº·t thÃ nh True khi báº¡n Ä‘Ã£ cáº¥u hÃ¬nh token vÃ  chat ID

# Cáº¥u hÃ¬nh logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler("markdown_crawler.log", encoding="utf-8"),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger("markdown_crawler")

def send_telegram_message(message):
    """
    Gá»­i tin nháº¯n tá»›i Telegram Bot
    
    Args:
        message (str): Ná»™i dung tin nháº¯n
    """
    if not ENABLE_TELEGRAM:
        return
        
    try:
        url = f"https://api.telegram.org/bot{TELEGRAM_BOT_TOKEN}/sendMessage"
        payload = {
            "chat_id": TELEGRAM_CHAT_ID,
            "text": message,
            "parse_mode": "HTML"
        }
        response = requests.post(url, data=payload)
        response.raise_for_status()
    except Exception as e:
        logger.error(f"Lá»—i khi gá»­i tin nháº¯n Telegram: {str(e)}")

def fix_relative_urls(html_content, base_url):
    """
    Sá»­a cÃ¡c Ä‘Æ°á»ng dáº«n tÆ°Æ¡ng Ä‘á»‘i (../path) thÃ nh Ä‘Æ°á»ng dáº«n tuyá»‡t Ä‘á»‘i
    
    Args:
        html_content: Äá»‘i tÆ°á»£ng BeautifulSoup
        base_url: URL cÆ¡ sá»Ÿ cá»§a trang web
    """
    # Sá»­a cÃ¡c Ä‘Æ°á»ng dáº«n trong tháº» img
    for img in html_content.find_all('img'):
        if img.get('src'):
            img['src'] = urljoin(base_url, img['src'])
    
    # Sá»­a cÃ¡c Ä‘Æ°á»ng dáº«n trong tháº» a
    for a in html_content.find_all('a'):
        if a.get('href'):
            a['href'] = urljoin(base_url, a['href'])
    
    # Sá»­a cÃ¡c Ä‘Æ°á»ng dáº«n trong thuá»™c tÃ­nh style cÃ³ url()
    for tag in html_content.find_all(style=True):
        if 'url(' in tag['style']:
            style = tag['style']
            # TÃ¬m táº¥t cáº£ cÃ¡c url() trong style
            urls = re.findall(r'url\([\'"]?(.*?)[\'"]?\)', style)
            for url in urls:
                if not url.startswith(('http://', 'https://', 'data:')):
                    absolute_url = urljoin(base_url, url)
                    style = style.replace(f'url({url})', f'url({absolute_url})')
            tag['style'] = style
    
    return html_content

def crawl_and_convert_to_markdown(url):
    """
    Crawl content from a webpage and convert to markdown using BeautifulSoup.
    
    Args:
        url (str): URL of the webpage to crawl
        
    Returns:
        dict: Dictionary containing title and content
    """
    # ThÃªm User-Agent Ä‘á»ƒ trÃ¡nh bá»‹ cháº·n
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
    }
    
    try:
        # Láº¥y tÃªn miá»n cÆ¡ sá»Ÿ tá»« URL
        parsed_url = urlparse(url)
        base_url = f"{parsed_url.scheme}://{parsed_url.netloc}"
        
        # Gá»­i request Ä‘áº¿n URL
        response = requests.get(url, headers=headers)
        response.raise_for_status()  # Raise exception for HTTP errors
        
        # Parse HTML content
        soup = BeautifulSoup(response.text, 'html.parser')
        
        # TÃ¬m container chÃ­nh
        main_content = soup.select_one('.col-md-7.middle-col')
        
        if not main_content:
            error_msg = f"KhÃ´ng tÃ¬m tháº¥y ná»™i dung trong selector chá»‰ Ä‘á»‹nh táº¡i {url}"
            logger.warning(error_msg)
            send_telegram_message(f"âš ï¸ {error_msg}")
            return {
                "title": "Error",
                "content": "KhÃ´ng tÃ¬m tháº¥y ná»™i dung trong selector chá»‰ Ä‘á»‹nh.",
                "status": "error"
            }
        
        # Loáº¡i bá» cÃ¡c pháº§n tá»­ khÃ´ng mong muá»‘n
        unwanted_classes = [
            '.paging.paging-btn',
            '.list',
            '.vj-toc',
            '.vj-more',
            '.vj-note',
            '.box-new-title',
            '.box-new',
            '.box-slide',
            '.box-course',
            '.box-most-viewed',
            '.all-list',
            '._2pi8'
        ]
        
        # Láº·p qua tá»«ng class vÃ  xÃ³a táº¥t cáº£ cÃ¡c pháº§n tá»­ cÃ³ class Ä‘Ã³
        for selector in unwanted_classes:
            while True:
                # TÃ¬m pháº§n tá»­ Ä‘áº§u tiÃªn cÃ³ class hiá»‡n táº¡i
                element = main_content.select_one(selector)
                if not element:
                    # KhÃ´ng cÃ²n pháº§n tá»­ nÃ o vá»›i class nÃ y
                    break
                # XÃ³a pháº§n tá»­
                element.decompose()
        
        # Sá»­a Ä‘Æ°á»ng dáº«n tÆ°Æ¡ng Ä‘á»‘i thÃ nh tuyá»‡t Ä‘á»‘i
        main_content = fix_relative_urls(main_content, url)
        
        # Chuyá»ƒn Ä‘á»•i HTML sang markdown
        converter = html2text.HTML2Text()
        converter.ignore_links = False
        converter.ignore_images = False
        converter.body_width = 0  # KhÃ´ng ngáº¯t dÃ²ng
        markdown_content = converter.handle(str(main_content))
        
        # Láº¥y tiÃªu Ä‘á» bÃ i viáº¿t náº¿u cÃ³
        title_element = main_content.select_one('h1')
        title = title_element.text.strip() if title_element else "KhÃ´ng cÃ³ tiÃªu Ä‘á»"
        
        return {
            "title": title,
            "content": markdown_content,
            "status": "success"
        }
    
    except requests.exceptions.RequestException as e:
        error_msg = f"Lá»—i khi crawl {url}: {str(e)}"
        logger.error(error_msg)
        send_telegram_message(f"âŒ {error_msg}")
        return {
            "title": "Error",
            "content": f"Lá»—i khi crawl dá»¯ liá»‡u: {str(e)}",
            "status": "error"
        }

def create_filename_from_url(url, title):
    """
    Táº¡o tÃªn file tá»« URL vÃ  tiÃªu Ä‘á»
    
    Args:
        url (str): URL cá»§a trang web
        title (str): TiÃªu Ä‘á» bÃ i viáº¿t
    
    Returns:
        str: TÃªn file há»£p lá»‡
    """
    # Láº¥y pháº§n cuá»‘i cá»§a URL (khÃ´ng bao gá»“m Ä‘uÃ´i)
    path = urlparse(url).path
    filename = os.path.splitext(os.path.basename(path))[0]
    
    # Náº¿u filename rá»—ng, sá»­ dá»¥ng tiÃªu Ä‘á»
    if not filename:
        filename = title
    
    # Loáº¡i bá» cÃ¡c kÃ½ tá»± khÃ´ng há»£p lá»‡
    filename = re.sub(r'[^\w\s-]', '', filename)
    filename = re.sub(r'[\s-]+', '-', filename).strip('-')
    
    return filename + '.md'

def load_urls_from_json(json_file):
    """
    Äá»c danh sÃ¡ch URL tá»« file JSON
    
    Args:
        json_file (str): ÄÆ°á»ng dáº«n Ä‘áº¿n file JSON
    
    Returns:
        list: Danh sÃ¡ch URL
    """
    try:
        with open(json_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        # Kiá»ƒm tra cáº¥u trÃºc cá»§a file JSON vÃ  trÃ­ch xuáº¥t URL
        urls = []
        if isinstance(data, list):
            # Náº¿u JSON lÃ  má»™t máº£ng
            for item in data:
                if isinstance(item, str):
                    # Náº¿u item lÃ  string (URL trá»±c tiáº¿p)
                    urls.append(item)
                elif isinstance(item, dict) and 'url' in item:
                    # Náº¿u item lÃ  Ä‘á»‘i tÆ°á»£ng cÃ³ thuá»™c tÃ­nh url
                    urls.append(item['url'])
        elif isinstance(data, dict):
            # Náº¿u JSON lÃ  má»™t Ä‘á»‘i tÆ°á»£ng
            if 'urls' in data and isinstance(data['urls'], list):
                # Náº¿u cÃ³ thuá»™c tÃ­nh urls lÃ  máº£ng
                urls = data['urls']
            elif 'links' in data and isinstance(data['links'], list):
                # Náº¿u cÃ³ thuá»™c tÃ­nh links lÃ  máº£ng
                urls = data['links']
        
        return urls
    
    except Exception as e:
        error_msg = f"Lá»—i khi Ä‘á»c file JSON {json_file}: {str(e)}"
        logger.error(error_msg)
        send_telegram_message(f"âŒ {error_msg}")
        return []

def load_checkpoint(checkpoint_file):
    """
    Äá»c danh sÃ¡ch URL Ä‘Ã£ crawl tá»« file checkpoint
    
    Args:
        checkpoint_file (str): ÄÆ°á»ng dáº«n Ä‘áº¿n file checkpoint
    
    Returns:
        set: Táº­p há»£p cÃ¡c URL Ä‘Ã£ crawl
    """
    try:
        if os.path.exists(checkpoint_file):
            with open(checkpoint_file, 'r', encoding='utf-8') as f:
                return set(json.load(f))
        return set()
    except Exception as e:
        error_msg = f"Lá»—i khi Ä‘á»c file checkpoint {checkpoint_file}: {str(e)}"
        logger.error(error_msg)
        send_telegram_message(f"âŒ {error_msg}")
        return set()

def save_checkpoint(checkpoint_file, crawled_urls):
    """
    LÆ°u danh sÃ¡ch URL Ä‘Ã£ crawl vÃ o file checkpoint
    
    Args:
        checkpoint_file (str): ÄÆ°á»ng dáº«n Ä‘áº¿n file checkpoint
        crawled_urls (set): Táº­p há»£p cÃ¡c URL Ä‘Ã£ crawl
    """
    try:
        with open(checkpoint_file, 'w', encoding='utf-8') as f:
            json.dump(list(crawled_urls), f, ensure_ascii=False, indent=2)
        logger.info(f"ÄÃ£ lÆ°u checkpoint vÃ o {checkpoint_file}")
    except Exception as e:
        error_msg = f"Lá»—i khi lÆ°u file checkpoint {checkpoint_file}: {str(e)}"
        logger.error(error_msg)
        send_telegram_message(f"âŒ {error_msg}")

def extract_path_components(json_path):
    """
    TrÃ­ch xuáº¥t cÃ¡c thÃ nh pháº§n Ä‘Æ°á»ng dáº«n tá»« Ä‘Æ°á»ng dáº«n file JSON
    
    Args:
        json_path (str): ÄÆ°á»ng dáº«n Ä‘áº¿n file JSON
    
    Returns:
        dict: CÃ¡c thÃ nh pháº§n Ä‘Æ°á»ng dáº«n
    """
    # Chuáº©n hÃ³a Ä‘Æ°á»ng dáº«n Ä‘á»ƒ lÃ m viá»‡c vá»›i táº¥t cáº£ cÃ¡c há»‡ Ä‘iá»u hÃ nh
    json_path = os.path.normpath(json_path)
    parts = json_path.split(os.sep)
    
    # TÃ¬m cÃ¡c pháº§n trong Ä‘Æ°á»ng dáº«n
    lop = ""
    mon = ""
    
    for i, part in enumerate(parts):
        if part.startswith("lop-"):
            lop = part
            if i+1 < len(parts):
                mon = parts[i+1]
    
    return {
        "lop": lop,
        "mon": mon
    }

def create_output_directory(json_path):
    """
    Táº¡o thÆ° má»¥c Ä‘áº§u ra dá»±a trÃªn Ä‘Æ°á»ng dáº«n file JSON
    
    Args:
        json_path (str): ÄÆ°á»ng dáº«n Ä‘áº¿n file JSON
    
    Returns:
        str: ÄÆ°á»ng dáº«n Ä‘áº¿n thÆ° má»¥c Ä‘áº§u ra
    """
    # Láº¥y cÃ¡c thÃ nh pháº§n Ä‘Æ°á»ng dáº«n
    components = extract_path_components(json_path)
    lop = components["lop"]
    mon = components["mon"]
    
    # Táº¡o Ä‘Æ°á»ng dáº«n Ä‘áº¿n thÆ° má»¥c Ä‘áº§u ra
    json_dir = os.path.dirname(json_path)
    output_dir = os.path.join(json_dir, "markdown")
    
    # Táº¡o thÆ° má»¥c náº¿u chÆ°a tá»“n táº¡i
    Path(output_dir).mkdir(exist_ok=True, parents=True)
    
    return output_dir

def find_json_files(base_dir, lop_range=range(1,2), mon_choices=["tieng_viet", "toan"]):
    """
    TÃ¬m táº¥t cáº£ cÃ¡c file JSON content_links.json trong thÆ° má»¥c
    
    Args:
        base_dir (str): ThÆ° má»¥c cÆ¡ sá»Ÿ Ä‘á»ƒ tÃ¬m kiáº¿m
        lop_range (range): Pháº¡m vi lá»›p cáº§n tÃ¬m
        mon_choices (list): Danh sÃ¡ch cÃ¡c mÃ´n há»c cáº§n tÃ¬m
        
    Returns:
        list: Danh sÃ¡ch Ä‘Æ°á»ng dáº«n Ä‘áº¿n cÃ¡c file JSON
    """
    json_files = []
    
    for lop_choice in lop_range:
        lop = f"lop-{lop_choice}"
        lop_dir = os.path.join(base_dir, lop)
        
        if not os.path.isdir(lop_dir):
            continue
            
        for mon in mon_choices:
            # TÃ¬m táº¥t cáº£ cÃ¡c thÆ° má»¥c con trong thÆ° má»¥c mÃ´n há»c
            mon_dir = os.path.join(lop_dir, mon)
            
            if not os.path.isdir(mon_dir):
                continue
                
            # Duyá»‡t qua táº¥t cáº£ thÆ° má»¥c con trong thÆ° má»¥c mÃ´n há»c
            for root, dirs, files in os.walk(mon_dir):
                if "content_links.json" in files:
                    json_files.append(os.path.join(root, "content_links.json"))
    
    return json_files

def main():
    # Thá»i gian báº¯t Ä‘áº§u
    start_time = datetime.now()
    
    # Banner
    banner = """
    =========================================================
    =            CRAWLER VIETJACK TO MARKDOWN              =
    =                  PHIÃŠN Báº¢N Lá»šP 1                  =
    =========================================================
    """
    
    logger.info(banner)
    
    # Gá»­i thÃ´ng bÃ¡o báº¯t Ä‘áº§u
    start_msg = f"ğŸš€ <b>Báº®T Äáº¦U CRAWL VIETJACK TO MARKDOWN</b>\n" \
               f"â° Thá»i gian: {start_time.strftime('%Y-%m-%d %H:%M:%S')}"
    send_telegram_message(start_msg)
    
    # ÄÆ°á»ng dáº«n máº·c Ä‘á»‹nh cho thÆ° má»¥c crawl
    base_dir = "."  # Thay Ä‘á»•i náº¿u cáº§n
    
    # Thá»‘ng kÃª
    stats = {
        "total_files": 0,
        "processed_files": 0,
        "total_urls": 0,
        "processed_urls": 0,
        "skipped_urls": 0,
        "failed_urls": 0
    }
    
    # TÃ¬m táº¥t cáº£ cÃ¡c file JSON cáº§n xá»­ lÃ½
    json_files = find_json_files(base_dir)
    
    if not json_files:
        error_msg = "KhÃ´ng tÃ¬m tháº¥y file JSON content_links.json nÃ o!"
        logger.error(error_msg)
        send_telegram_message(f"âš ï¸ {error_msg}")
        return
    
    stats["total_files"] = len(json_files)
    logger.info(f"TÃ¬m tháº¥y {len(json_files)} file JSON cáº§n xá»­ lÃ½")
    send_telegram_message(f"ğŸ” TÃ¬m tháº¥y {len(json_files)} file JSON cáº§n xá»­ lÃ½")
    
    # Láº·p qua táº¥t cáº£ cÃ¡c file JSON
    for file_index, json_path in enumerate(json_files, 1):
        # Láº¥y thÃ´ng tin lá»›p vÃ  mÃ´n há»c tá»« Ä‘Æ°á»ng dáº«n
        components = extract_path_components(json_path)
        lop = components["lop"]
        mon = components["mon"]
        
        # Hiá»ƒn thá»‹ tÃªn mÃ´n há»c Ä‘áº¹p hÆ¡n
        display_mon = "Tiáº¿ng Viá»‡t" if mon == "tieng_viet" else "ToÃ¡n"
        
        logger.info(f"\n=== [{file_index}/{len(json_files)}] Äang xá»­ lÃ½: {lop} - {display_mon} ===")
        send_telegram_message(f"ğŸ“‚ <b>Äang xá»­ lÃ½ ({file_index}/{len(json_files)}):</b> {lop} - {display_mon}")
        
        try:
            # Kiá»ƒm tra xem file JSON cÃ³ tá»“n táº¡i khÃ´ng
            if not os.path.exists(json_path):
                logger.warning(f"KhÃ´ng tÃ¬m tháº¥y file JSON táº¡i Ä‘Æ°á»ng dáº«n: {json_path}")
                continue  # Bá» qua vÃ  tiáº¿p tá»¥c vá»›i mÃ´n/lá»›p tiáº¿p theo
            
            # Táº¡o thÆ° má»¥c Ä‘áº§u ra
            output_dir = create_output_directory(json_path)
            
            # Táº¡o file checkpoint
            checkpoint_file = os.path.join(output_dir, "checkpoint.json")
            
            # Äá»c danh sÃ¡ch URL Ä‘Ã£ crawl tá»« file checkpoint
            crawled_urls = load_checkpoint(checkpoint_file)
            
            # Äá»c danh sÃ¡ch URL tá»« file JSON
            all_urls = load_urls_from_json(json_path)
            
            if not all_urls:
                warning_msg = f"KhÃ´ng tÃ¬m tháº¥y URL nÃ o trong file {json_path}"
                logger.warning(warning_msg)
                send_telegram_message(f"âš ï¸ {warning_msg}")
                continue  # Bá» qua vÃ  tiáº¿p tá»¥c vá»›i mÃ´n/lá»›p tiáº¿p theo
            
            # Lá»c cÃ¡c URL chÆ°a crawl
            urls_to_crawl = [url for url in all_urls if url not in crawled_urls]
            
            stats["total_urls"] += len(all_urls)
            stats["skipped_urls"] += len(crawled_urls)
            
            logger.info(f"Tá»•ng sá»‘ URL: {len(all_urls)}")
            logger.info(f"Sá»‘ URL Ä‘Ã£ crawl: {len(crawled_urls)}")
            logger.info(f"Sá»‘ URL cáº§n crawl: {len(urls_to_crawl)}")
            
            # Gá»­i thÃ´ng bÃ¡o sá»‘ lÆ°á»£ng URL cáº§n crawl
            urls_info_msg = f"ğŸ“Š <b>{lop} - {display_mon}:</b>\n" \
                           f"- Tá»•ng sá»‘ URL: {len(all_urls)}\n" \
                           f"- URL Ä‘Ã£ crawl: {len(crawled_urls)}\n" \
                           f"- URL cáº§n crawl: {len(urls_to_crawl)}"
            send_telegram_message(urls_info_msg)
            
            if not urls_to_crawl:
                logger.info("Táº¥t cáº£ URL Ä‘Ã£ Ä‘Æ°á»£c crawl!")
                continue  # Bá» qua vÃ  tiáº¿p tá»¥c vá»›i mÃ´n/lá»›p tiáº¿p theo
            
            # Sá»‘ URL thÃ nh cÃ´ng vÃ  tháº¥t báº¡i trong file nÃ y
            successful_count = 0
            failed_count = 0
            
            # Crawl tá»«ng URL vÃ  lÆ°u vÃ o file markdown
            for i, url in enumerate(urls_to_crawl, 1):
                logger.info(f"[{i}/{len(urls_to_crawl)}] Äang crawl: {url}")
                
                try:
                    result = crawl_and_convert_to_markdown(url)
                    
                    if result["status"] == "success":
                        # Táº¡o tÃªn file tá»« URL hoáº·c tiÃªu Ä‘á»
                        filename = create_filename_from_url(url, result["title"])
                        file_path = os.path.join(output_dir, filename)
                        
                        # LÆ°u ná»™i dung vÃ o file
                        with open(file_path, 'w', encoding='utf-8') as f:
                            # ThÃªm tiÃªu Ä‘á» vÃ o Ä‘áº§u file markdown
                            f.write(f"# {result['title']}\n\n")
                            f.write(result["content"])
                        
                        logger.info(f"ÄÃ£ lÆ°u ná»™i dung vÃ o file {file_path}")
                        
                        # ThÃªm URL vÃ o danh sÃ¡ch Ä‘Ã£ crawl
                        crawled_urls.add(url)
                        successful_count += 1
                        
                        # LÆ°u checkpoint sau má»—i 5 URL hoáº·c khi crawl URL cuá»‘i cÃ¹ng
                        if i % 5 == 0 or i == len(urls_to_crawl):
                            save_checkpoint(checkpoint_file, crawled_urls)
                            
                            # Gá»­i thÃ´ng bÃ¡o tiáº¿n Ä‘á»™ sau má»—i 5 URL
                            progress_msg = f"ğŸ”„ <b>{lop} - {display_mon}:</b> ÄÃ£ xá»­ lÃ½ {i}/{len(urls_to_crawl)} URL"
                            send_telegram_message(progress_msg)
                    else:
                        logger.error(f"Lá»—i khi xá»­ lÃ½ URL {url}: {result['content']}")
                        failed_count += 1
                
                except Exception as e:
                    error_msg = f"Lá»—i khÃ´ng xÃ¡c Ä‘á»‹nh khi xá»­ lÃ½ URL {url}: {str(e)}"
                    logger.error(error_msg)
                    send_telegram_message(f"âŒ {error_msg}")
                    failed_count += 1
                
                # Nghá»‰ má»™t chÃºt Ä‘á»ƒ trÃ¡nh bá»‹ cháº·n
                time.sleep(1)
            
            # LÆ°u checkpoint cuá»‘i cÃ¹ng
            save_checkpoint(checkpoint_file, crawled_urls)
            
            # Cáº­p nháº­t thá»‘ng kÃª
            stats["processed_urls"] += successful_count
            stats["failed_urls"] += failed_count
            stats["processed_files"] += 1
            
            # Gá»­i thÃ´ng bÃ¡o hoÃ n thÃ nh file
            complete_msg = f"âœ… <b>HoÃ n thÃ nh {lop} - {display_mon}:</b>\n" \
                          f"- ÄÃ£ crawl thÃ nh cÃ´ng: {successful_count}/{len(urls_to_crawl)} URL\n" \
                          f"- Lá»—i: {failed_count} URL\n" \
                          f"- LÆ°u táº¡i: {output_dir}"
            
            logger.info(f"HoÃ n thÃ nh! ÄÃ£ crawl vÃ  lÆ°u {successful_count} trang vÃ o thÆ° má»¥c {output_dir}")
            send_telegram_message(complete_msg)
            
        except Exception as e:
            error_msg = f"Lá»—i khÃ´ng xÃ¡c Ä‘á»‹nh khi xá»­ lÃ½ file {json_path}: {str(e)}"
            logger.error(error_msg)
            send_telegram_message(f"âŒ {error_msg}")
    
    # Thá»i gian káº¿t thÃºc
    end_time = datetime.now()
    duration = end_time - start_time
    
    # Gá»­i thÃ´ng bÃ¡o hoÃ n thÃ nh toÃ n bá»™
    final_msg = f"ğŸ‰ <b>HOÃ€N THÃ€NH TOÃ€N Bá»˜ CÃ”NG VIá»†C</b>\n" \
               f"â° Thá»i gian báº¯t Ä‘áº§u: {start_time.strftime('%Y-%m-%d %H:%M:%S')}\n" \
               f"â° Thá»i gian káº¿t thÃºc: {end_time.strftime('%Y-%m-%d %H:%M:%S')}\n" \
               f"â±ï¸ Tá»•ng thá»i gian: {str(duration).split('.')[0]}\n" \
               f"ğŸ“Š <b>Thá»‘ng kÃª:</b>\n" \
               f"- Files Ä‘Ã£ xá»­ lÃ½: {stats['processed_files']}/{stats['total_files']}\n" \
               f"- URL Ä‘Ã£ crawl: {stats['processed_urls']}\n" \
               f"- URL bá» qua (Ä‘Ã£ crawl trÆ°á»›c Ä‘Ã³): {stats['skipped_urls']}\n" \
               f"- URL lá»—i: {stats['failed_urls']}\n" \
               f"- Tá»•ng URL: {stats['total_urls']}"
    
    logger.info("\n=== Káº¾T QUáº¢ CUá»I CÃ™NG ===")
    logger.info(f"Files Ä‘Ã£ xá»­ lÃ½: {stats['processed_files']}/{stats['total_files']}")
    logger.info(f"URL Ä‘Ã£ crawl: {stats['processed_urls']}")
    logger.info(f"URL bá» qua (Ä‘Ã£ crawl trÆ°á»›c Ä‘Ã³): {stats['skipped_urls']}")
    logger.info(f"URL lá»—i: {stats['failed_urls']}")
    logger.info(f"Tá»•ng URL: {stats['total_urls']}")
    logger.info(f"Tá»•ng thá»i gian: {str(duration).split('.')[0]}")
    logger.info("=== HOÃ€N THÃ€NH ===")
    
    send_telegram_message(final_msg)

if __name__ == "__main__":
    main()